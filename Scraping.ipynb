{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b46ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d116de97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple request on webpage\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6577ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9f0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<!DOCTYPE html>',\n",
       " '<html>',\n",
       " '    <head>',\n",
       " '        <title>A simple example page</title>',\n",
       " '    </head>',\n",
       " '    <body>',\n",
       " '        <p>Here is some simple content for this page.</p>',\n",
       " '    </body>',\n",
       " '</html>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formating \n",
    "page.text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e67b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'example.txt' was not found and has been created.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to read from a file\n",
    "try:\n",
    "    with open('example.txt', 'r') as file:\n",
    "        content = file.read()\n",
    "        print(content)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create it and write a default message\n",
    "    with open('example.txt', 'w') as file:\n",
    "        file.write(\"This is a new file.\")\n",
    "        print(\"File 'example.txt' was not found and has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7315a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d69a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "BeautifulSoup\n",
      "example.txt\n",
      "Scrapy\n",
      "Selenium\n",
      "Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#list all files in a directory\n",
    "for file in os.listdir('/Users/bapti/OneDrive/Documents/Hitema/M1 WEB/Python WEBSCRAPING'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e644aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b93d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"name\": \"Alice Brown\",\n",
    "        \"department\": \"Marketing\",\n",
    "        \"salary\": 70000\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bob Smith\",\n",
    "        \"department\": \"Sales\",\n",
    "        \"salary\": 65000\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Carol Jones\",\n",
    "        \"department\": \"IT\",\n",
    "        \"salary\": 75000\n",
    "    }\n",
    "]\n",
    "\n",
    "#write this variable inside a json file\n",
    "with open('output.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30224fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice Brown', 'department': 'Marketing', 'salary': 70000}, {'name': 'Bob Smith', 'department': 'Sales', 'salary': 65000}, {'name': 'Carol Jones', 'department': 'IT', 'salary': 75000}]\n"
     ]
    }
   ],
   "source": [
    "with open('output.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086b4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import csv\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "710aef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Traditional approach took: 0.018683195114135742 seconds\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def csv_reader(file_content):\n",
    "    return csv.reader(StringIO(file_content))\n",
    "\n",
    "# Fetch the file content from the URL\n",
    "url = 'https://gist.githubusercontent.com/bdallard/d4a3e247e8a739a329fd518c0860f8a8/raw/82fb43adc5ce022797a5df21eb06dd8e755145ea/data-json.csv'\n",
    "response = requests.get(url)\n",
    "file_content = response.text\n",
    "\n",
    "tmp=0\n",
    "start_time = time.time()\n",
    "csv_data = csv_reader(file_content)\n",
    "for row in csv_data:\n",
    "    tmp+=int(row[0][-1]) #some dummy operation\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Traditional approach took:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f657b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://httpbin.org/ip') \n",
    "#print(response.json()['origin']) #your personnal ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f248c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting free-proxy\n",
      "  Downloading free_proxy-1.1.1.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: lxml in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from free-proxy) (4.9.3)\n",
      "Requirement already satisfied: requests in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from free-proxy) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from requests->free-proxy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from requests->free-proxy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from requests->free-proxy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bapti\\anaconda3\\lib\\site-packages (from requests->free-proxy) (2023.11.17)\n",
      "Building wheels for collected packages: free-proxy\n",
      "  Building wheel for free-proxy (setup.py): started\n",
      "  Building wheel for free-proxy (setup.py): finished with status 'done'\n",
      "  Created wheel for free-proxy: filename=free_proxy-1.1.1-py3-none-any.whl size=5663 sha256=5a91123f378c8241f3d536e800aea98399cd2e230d604636c0ebd671908d8639\n",
      "  Stored in directory: c:\\users\\bapti\\appdata\\local\\pip\\cache\\wheels\\c6\\7f\\3f\\b764995ae2502d8642977764577198043d3b6c6738534f5ffe\n",
      "Successfully built free-proxy\n",
      "Installing collected packages: free-proxy\n",
      "Successfully installed free-proxy-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install free-proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e081b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fp.fp import FreeProxy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96866ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://202.131.65.110:80'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy = FreeProxy(country_id=['FR']).get(); proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8121d139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://109.108.40.238:8090',\n",
       " 'http://185.212.60.62:80',\n",
       " 'http://2.58.56.39:80']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_list = [FreeProxy(country_id=['FR']).get() for x in range(3)]; proxy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87820951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.28.219.140\n"
     ]
    }
   ],
   "source": [
    "proxies = {'http': proxy_list[1]} \n",
    "response = requests.get('http://httpbin.org/ip', proxies=proxies) \n",
    "print(response.json()['origin']) # our proxy !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0080b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.31.0', 'X-Amzn-Trace-Id': 'Root=1-66014b0c-28d90e074700ec894a7b630b'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('http://httpbin.org/headers') \n",
    "print(response.json()['headers'])\n",
    "# python-requests/2.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c69823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
